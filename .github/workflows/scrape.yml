name: scrape
on:
  workflow_dispatch:
  schedule:
    - cron: '* */8 * * *'
jobs:
  scrape_and_email:
    runs-on: ubuntu-latest
    steps:
      - name: Check out this repo
        uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
      - name: Install all necessary packages
        run: pip install requests beautifulsoup4 pandas sendgrid
      - name: Run the scraping script
        run: python scraper_DW.py
      - name: Commit and push and email if content changed
        env:
          SENDGRID_API_KEY: ${{ secrets.SENDGRID_API_KEY }}
          FROM_EMAIL: ${{ secrets.FROM_EMAIL }}
          TO_EMAIL: ${{ secrets.TO_EMAIL }}
        run: |-
          git config user.name "Automated"
          git config user.email "actions@users.noreply.github.com"
          git add -A
          timestamp=$(date -u)
          git commit -m "Latest data: ${timestamp}" &&
            export COMMIT_HASH=$(git rev-parse HEAD) &&
            python send_mail.py ||
            exit 0
          git push